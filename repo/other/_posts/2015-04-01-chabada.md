---
title: chabada
excerpt: "Checking App Behavior Against App Descriptions"
layout: repo-dataset
authors: "Alessandra Gorla; Ilaria Tavecchia; Florian Gross; Andreas Zeller"
version: 4
---

#URL

* [Data in Terapromise](https://terapromise.csc.ncsu.edu:8443/!/#repo/view/head/other/chabada)
* [Paper in ACM Digital Library](http://dl.acm.org/citation.cfm?id=2568276)

#Change Log

When | What
---- | ----
April 1st, 2015 | Donated by [Alessandra Gorla](/repo/people/data-donors/promise4.html)

#Reference

Studies who have been using the data (in any form) are required to include the following reference:

```
@inproceedings{GorlaetAl:CHABADA:ICSE:2014, 
  author = {Alessandra Gorla and Ilaria Tavecchia and Florian Gross and Andreas Zeller},
  title = {Checking App Behavior Against App Descriptions},
  booktitle = {ICSE'14: Proceedings of the 36th International Conference on Software Engineering}, 
  location = {Hyderabad (India), 31 May - 7 June}, 
  year = {2014}, 
}
```

#About the Data

##Overview of Data

How do we know a program does what it claims to do? After clustering Android apps by their 
description topics, we identify outliers in each cluster with respect to their API usage. A 
"weather" app that sends messages thus becomes an anomaly; likewise, a "messaging" app would 
typically not be expected to access the current location. Applied on a set of 22,500+ Android 
applications, our CHABADA prototype identified several anomalies; additionally, it flagged 56% 
of novel malware as such, without requiring any known malware patterns.

